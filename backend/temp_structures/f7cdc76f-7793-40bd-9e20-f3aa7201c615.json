[{"epochs": 5, "dtype": "fp32"}, {"type": "tokenEmbedding", "data": {"id": "embed_1", "label": "Token Embedding", "vocabSize": 50257, "embDim": 768}}, {"type": "positionalEmbedding", "data": {"id": "pos_1", "label": "Positional Embedding", "embDim": 768, "ctxLength": 1024}}, {"type": "transformerBlock", "data": {"id": "transformer_1", "label": "Transformer Block", "numOfBlocks": 2}, "children": [{"type": "attention", "data": {"id": "attn_1", "label": "Self Attention", "inDim": 768, "outDim": 768, "num_heads": 12, "ctxLength": 1024, "attn_type": "default", "dropout": 0.1, "qkv_bias": true}}, {"type": "normalization", "data": {"id": "norm_1", "label": "Layer Norm 1"}}, {"type": "feedForward", "data": {"id": "ffn_1", "label": "Feed Forward Network", "numOfFactor": 4}}, {"type": "normalization", "data": {"id": "norm_2", "label": "Layer Norm 2"}}, {"type": "residual", "data": {"id": "residual_1", "label": "Residual Connection", "source": "attn_1"}}]}, {"type": "linear", "data": {"id": "output_1", "label": "Output Layer", "inDim": 768, "outDim": 50257}}]