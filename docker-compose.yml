services:
  redis:
    image: redis:7-alpine
    container_name: slm-redis
    ports: ["6379:6379"]
    volumes: ["redis_data:/data"]
    restart: unless-stopped

  mlflow:
    image: ghcr.io/mlflow/mlflow:v3.3.2 # ← v 프리픽스 필수
    container_name: slm-mlflow
    command: >
      mlflow server --host 0.0.0.0 --port 5000
      --backend-store-uri sqlite:////mlflow/mlflow.db
      --default-artifact-root /mlflow/artifacts
    volumes:
      - mlflow_data:/mlflow
    ports: ["5000:5000"]
    restart: unless-stopped

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: slm-backend
    working_dir: /app/backend
    environment:
      - REDIS_URL=redis://redis:6379/0
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./backend:/app/backend # 코드 저장 시 즉시 반영 (uvicorn --reload)
      - ./backend/model_structures:/app/backend/model_structures # 모델 구조를 로컬에서도 확인
      - mlflow_data:/mlflow:rw # (필요 시) mlflow 경로 공유
    depends_on: [redis, mlflow]
    ports: ["8000:8000"]
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    restart: unless-stopped

  worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: slm-celery-worker
    working_dir: /app/backend
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - REDIS_URL=redis://redis:6379/0
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./backend:/app/backend # 코드 변경 시 자동 재시작 감지
      - ./backend/model_structures:/app/backend/model_structures # 모델 구조를 로컬에서도 확인
      - mlflow_data:/mlflow:rw
    depends_on: [redis, mlflow, backend]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all          # 모든 GPU 사용
              capabilities: [gpu]
    command: >
      watchmedo auto-restart
      --directory=/app/backend
      --pattern="*.py"
      --recursive --
      celery -A celery_worker.celery_app worker --loglevel=info
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: slm-frontend
    working_dir: /app/frontend
    environment:
      - VITE_API_BASE=http://localhost:8000
      - CHOKIDAR_USEPOLLING=true # WSL/도커 파일감시 보정
      - CHOKIDAR_INTERVAL=100
    volumes:
      - ./frontend:/app/frontend\ # node_modules를 마운트하지 않고 새로 라이브러리 추가 시 재빌드
    depends_on: [backend]
    ports: ["5173:5173"]
    command: npm run dev -- --host 0.0.0.0
    restart: unless-stopped

volumes:
  redis_data:
  mlflow_data:
  frontend_node_modules: